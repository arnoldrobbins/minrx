MinRX is an Non-deterministic Finite Automaton (NFA) based regular
expression matcher that introduces a new algorithm and automaton
structure for computing the matching substrings of POSIX Extended Regular
Expressions (EREs).  I call this enhanced automaton a Structured NFA,
abbreviated SNFA.  It could also possibly be called a Stacked NFA with
the same abbreviation.

As is conventional, the SNFA includes both nodes that consume and match
input characters (from the string being searched), as well as nodes,
called epsilon-matching nodes, that "match the empty string" and do not
consume input characters.

As is also conventional, the matching algorithm maintains a set of
"threads" exploring all possible paths through the SNFA in parallel.
The matcher performs a breadth-first search of paths through the SNFA,
advancing all threads one input character at a time.

The matcher is initialized by introducing a single thread associated
with the initial entry node (a.k.a. start state) of the SNFA.  Then the
matcher performs an "epsilon closure", exhaustively finding the set of
all nodes reachable from the start state by traversing outgoing edges of
only epsilon-matching nodes.  The output of this initial epsilon closure
is the initial state of the matcher prior to the first input character.

After initialization the matcher loops over input characters, performing
the following operations for each input character:

  * discard all threads at epsilon-matching nodes

  * advance only those remaining threads at character-matching nodes
    that actually match the current input character

  * introduce a new thread at the start state (in order to explore
    matches at all possible starting offsets in the search string)

  * perform epsilon closure on the set of threads

These steps are repeated until there are no more input characters.

If the Exit node of the SNFA is reached during this process, then a
match has been found and the algorithm will prioritize it against any
other matches that have also been found in order to identify the "best"
match, according to criteria that will be described later.

One last conventional aspect of this matcher is that every thread records
the starting and ending offsets, within the input string, corresponding
to parenthesized subexpression groups encountered previously along
that thread's path through the SNFA.  Each thread is also labeled with
the position in the input string at which the thread was introduced to
the search.  Whenever two threads reach the same node in the SNFA, only
the thread that originated earlier in the search string is retained.
If two threads with the same starting position reach the same node,
additional criteria described later determine which will be retained.

This is all very conventional, so what is different about regular expression
matching using the SNFA?

  * Each thread traversing the SNFA records a stack of integer values that
    drive disambiguation of POSIX subpattern matches.  In contrast to the
    stacked automata of parsing theory, such as LR parsers, the stacks
    of threads traversing the SNFA are finite and bounded.  The thread
    stacks exist alongside the remembered starting and ending offsets of
    parenthesized subexpressions.  Importantly, only the initial starting
    offset and stack contents are used to determine which threads to
    retain and which to discard at each node in the SNFA.  The memorialized
    positions of parenthesized groups do not participate in these decisions.

  * Nodes of the SNFA retain a block structure corresponding to the syntax
    of the regular expression, with structure-delimiting nodes at the entry
    and exit points of alternations, closures/repetitions, and parenthesized
    subexpressions.  Each node of the SNFA has an associated stack depth.
    Stack entries are pushed when traversing edges from structure-entry nodes
    to nodes inside the structures, and are popped when traversing edges
    departing from structure-exiting nodes.

  * The epsilon-closure algorithm is modified to respect the SNFA's block
    structure as follows: the epsilon closure of all (node, thread)
    tuples inside each structured block is exhaustively expanded before
    any structure-exiting edges are traversed.  This invariant ensures
    that any thread state exiting a block structured construct at a
    particular character boundary has been compared to all other possible
    competing threads before it "escapes" to downstream/outside nodes.
    At each input character boundary, only the best solution to any
    block-structured construct survives to escape from each successively
    less-nested level of the regular expression's subexpression
    structure.  This is important because when stack entries are popped
    at structure-exiting nodes, the stack entries needed to prioritize
    threads with respect to the constraints of the now-exited structure
    are lost.

    There are a variety of ways that this ordering constraint on epsilon
    closure evaluation can be implemented.  In MinRX it is enforced
    by numbering the nodes from left to right according to the lexical
    position in the original regular expression, such that all structure-
    exiting nodes are higher-numbered than any nodes in the interiors of
    the structures they are exiting.  Then the queue of states waiting to
    be examined in the conventional epsilon-closure algorithm is replaced
    with a priority queue of states to be examined, so that of the not-
    yet-processed nodes, the lowest-numbered node will always be processed
    first.

  * In order to bound the storage of the search, whenever two threads
    reach the same node in the SNFA, only one is retained.  Recall that
    threads record the starting offset in the input string, their stacks,
    and the starting and ending offsets of parenthesized sub-expressions
    encountered previously in the history of the thread.  When comparing
    two threads to pick the winner at a particular SNFA node, if one
    of the threads has an earlier starting offset than the other, that
    thread will win.  Otherwise if both threads have the same starting
    offset, then the thread stacks will be compared to choose the winner.

    The SNFA is constructed with the extremely important property that
    at every node, the stack layouts of different arriving threads
    will be identical.  The stack comparison rule then is that stacks
    entries are compared in lexical scope order, from outermost (oldest)
    stack levels to inner (youngest) stack levels.  At each stack level,
    if the stack entries at that level of the two competing threads
    differ, the thread with the numerically larger stack entry value
    will be chosen as the winner.  Otherwise, the comparison proceeds
    to increasingly inner stack levels.

    Comparing stack entries lexically from outermost to innermost
    corresponds to the POSIX regular expression requirement that the
    best solution to the overall "outer" position and length of the
    whole regular expression takes precedence over the best solution(s)
    of the subpatterns, and this applies recursively to subpatterns of
    the subpatterns and so on.

In order to develop an intuition for how this works, we will look at
specific node types used in the syntax-directed translation of regular
expressions to MinRX SNFA nodes.  The translation scheme is almost
completely traditional:

* xlate[[ a|b ]]	=>	FORK xlate[[ a ]] GOTO xlate[[ b ]] JOIN
* xlate[[ a+ ]]		=>	LOOP xlate[[ a ]] NEXT
* xlate[[ ab ]]		=>	xlate[[ a ]] xlate[[ b ]]
* xlate[[ (a) ]]	=>	SUBL xlate[[ a ]] SUBR

Compared to classic NFA algorithms in the literature, the only difference
above is that parentheses in the source regular expression correspond
to epsilon-matching SUBL/SUBR nodes in the SNFA, whereas in classic NFA
algorithms parentheses do not appear in the NFA at all.

All of the node types mentioned above (FORK, GOTO, JOIN, LOOP, NEXT, SUBL,
and SUBR) are epsilon-matching node types.  All of the action of POSIX
subexpression selection happens at these epsilon-matching nodes.  The
actual character-matching nodes turn out to be not very interesting!

Now follows a description of the stack frames pushed and popped by each
of the structure-entering and structure-existing node types in MinRX:

  * A FORK node pushes a single stack entry, and a JOIN node pops it.
    The interior nodes of the FORK...JOIN construct as well as the JOIN
    node itself therefore have a stack depth 1 greater than the stack depth
    of the FORK node.  The FORK node additionally splits each thread into
    two threads for the left and right branches of the regular expression
    alternatives.  The value of the stack entry that is pushed is -1 on
    the thread sent to the left branch of the alternative, and -2 on the
    thread sent to the right branch of the alternative.  Then when the
    stacks of threads exiting the alternative are compared upon arriving
    at the JOIN node at any particular character boundary in the search
    string, in the absence of any overriding constraints inherited from
    enclosing structures the choose-greater rule in the FORK's stack
    entry comparison will cause threads joining from the left branch to
    take precedence over threads joining from the right branch.  This
    implements the POSIX rule preferring the left alternative.

    In order to minimize maximum stack depth, and since regular expression
    alternatives are equally left- and right-associative, MinRX actually
    supports FORK...JOIN constructs with arbitrarily many contained
    alternatives (separated by GOTO nodes) and pushes stack entry values
    of -1, -2, -3, and so on in each successive alternative.

  * A SUBL node pushes a single stack entry and SUBR pops it.  As with
    FORK...JOIN, the interior nodes of SUBL...SUBR therefore have a stack
    depth 1 greater than the stack depth of the SUBL node.  The value
    of the stack entry that is pushed is the offset within the string at
    the current point in the match at which the SUBL node is traversed.
    The choose-greater rule in stack entry comparison will ensure that
    if two threads exiting a SUBR at a particular character boundary are
    not otherwise disambiguated by inherited outer constraints, then the
    thread whose SUBL occured at a *later* point in the input string will
    be chosen.  In other words, the greater-than stack entry comparison
    rule chooses the SHORTER of the two exiting subexpressions' threads!

    Wait, what?  Isn't the POSIX requirement to recursively find LONGEST
    matches?  What's this shortest business doing???  The key observation
    is that picking the SHORTEST match for SUBL...SUBR has the effect of
    maximizing the length of input string previously matched to the LEFT
    of the SUBL.  This rule prioritizes longer matches for previous
    subpatterns in the regular expression.

    The stack frame pushed by SUBL serves an additional purpose besides
    picking winners: when a SUBR node corresponding to a user-inserted
    closing parenthesis is exited, the starting string position is popped
    from the stack and written, together with the current string position,
    into the thread's vector of recorded POSIX subexpression starting and
    ending offsets.  So (start, end) offsets don't appear in the thread's
    subexpression position vector until the thread has actually completed
    matching the entire subexpression.

  * LOOP...NEXT constructs are by far the most complicated and push three
    entries on the stack.  The outermost stack entry is the start offset
    (within the input string) at the time of initial entry to the loop.
    The next middle entry is the negated repeat count.  Finally the
    innermost stack entry is the starting offset of the most recent
    iteration of the loop.  When disambiguating multiple loop exits,
    these stack entries and their positions have the following effects:

      * The outermost stack entry, the position of the start of the loop,
	ensures that the overall shortest instance of the loop exiting
	at any character boundary will be picked, thus maximizing the
	length of material matched prior to the loop entry, as was also
	previously seen with the rule for SUBL...SUBR.

      * The next stack entry, the negated repeat count, ensures that
	for otherwise identical-length loop matches, the match with the
	fewest iterations will be chosen.  This corresponds to maximizing
	the lengths of earlier iterations.

      * Finally the last stack entry, the most recent loop start offset,
	ensures that in the case of identical repeat counts, the shortest
	match for the last repetition will be chosen, again corresponding
	to maximizing the length of earlier iterations.

    As with SUBL...SUBR, the stack entries belonging to LOOP...NEXT serve
    multiple uses.  The stacked most-recent-iteration starting offset
    is also used to eliminate repeated consecutive empty iterations
    of the loop.

That's (almost) all there is to it!

There is one potential refinement in the translation scheme that has not
yet been discussed that pertains to the associativity of concatenation.

Consider a regular expression of the form ABC, where A, B, and C
are subpatterns all of which can match material of variable length.
POSIX requires finding the leftmost longest overall solution to ABC.
But if for a particular search string there are multiple solutions for
the lengths of A, B, and C that yield the the same leftmost-longest
overall solution for ABC, which should be chosen?  Either we can try
to maximize AB at the expense of shortening C, or else we can try
to maximize A at the expense of shortening BC.

It turns out the POSIX standard is ambiguous about this situation.
The grammar in the standard for concatenated regular expressions is a
left-associative grammar.  However, there is an example in the rationale
(not officially part of the standard...) that assumes concatenation is
is right-associative.

The SNFA approach can implement either option for the associativity
of concatenation.  The default stack frames and translation scheme
described above turn out to implement left-associative concatenation:
material farther to the left is always maximized first, so in ABC,
AB will be maximized at the expense of C.

However the translation scheme can be modified to "insert parentheses"
as follows:

* xlate[[ abc ]]	=>	xlate[[ a ]] SUBL xlate[[ b ]] xlate[[ c ]] SUBR

At the cost of extra stack levels and epsilon transitions, now A will
be maximized at the expense of BC, corresponding to right-associativity.
This is achieved due to the stack entry string offset value pushed at SUBL
forcing the minimization of SUBL b c SUBR in favor of material to the
left of the SUBL.  (We would mark the extra SUBL...SUBR nodes inserted
in this fashion as invisible so that they don't show up as user-visible
numbered subexpressions with recorded positions in the output.)

MinRX currently implements left-associative concatentation, since it is
cheaper at both runtime and compile time, and is also consistent with the
behaviour of the repeated self-concatenation in duplication operators.
If there is popular demand for right-associative concatenation, or if
a future edition of the standard explicitly specifies right-associative
concatenation, that can be implemented in MinRX with a modest code change.

Some caveats:

  * This approach does not currently address the problem of POSIX Basic
    Regular Expressions including back-references.  I view BREs with
    backreferences as an (almost) completely unrelated problem, since
    they do not correspond to finite automata at all.  The algorithm
    described here could probably be straightforwardly modified to search
    for backreference expressions, but would lose the property that the
    maximum number of threads in flight is equal to the size of the NFA,
    and it would almost certainly require exponential space even in
    relatively simple cases, and so would be unlikely to be generally usable.

  * It should be noted this algorithm has not yet been proven correct,
    but it has no "special cases" and has passed a plethora of published
    tests, including a number tests that trip up almost all other extant
    attempts to implement POSIX ERE matchers.  I have high hopes for the
    ultimate success of this algorithm given the simplicity.

Future work:

  * Correctness proof and/or fix bugs until correctness proof is possible.
    (Or give up on this approach and look for new ideas...)

  * Implement a caching-DFA-like matcher based on this approach.  Certainly
    there is no direct DFA implementation, since thread stacks containing
    arbitrary counts would map to infinite numbers of automaton states.
    But there may be tricks to hoist count parameters out of the automaton
    states, or perhaps just cache (and regenerate upon demand) a finite
    subset of the states of a "Deterministic Infinite Automaton".
